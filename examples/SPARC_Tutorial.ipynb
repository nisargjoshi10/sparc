{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb21b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".tutorial-wrap{--bg:#f6f8fc;--panel:#ffffff;--panel-soft:rgba(255,255,255,.75);--stroke:rgba(16,24,40,.12);--text:#0f172a;--muted:rgba(15,23,42,.7);--accent:#2563eb;--radius:18px;font-family:system-ui,-apple-system,sans-serif;color:var(--text);padding:22px;margin:8px 0 18px;background:radial-gradient(1000px 500px at 15% 10%,rgba(37,99,235,.15),transparent 55%),radial-gradient(800px 450px at 85% 15%,rgba(124,58,237,.12),transparent 50%),var(--bg)}\n",
       ".hero-section{display:grid;grid-template-columns:1.2fr .8fr;gap:18px;align-items:center;padding:18px;border-radius:calc(var(--radius) - 6px);background:linear-gradient(135deg,var(--panel),var(--panel-soft))}\n",
       ".content-grid{margin-top:16px}\n",
       ".tutorial-title{margin:0;font-size:clamp(2.1rem,5vw,3rem);line-height:1.1}\n",
       ".tutorial-subtitle{margin:10px 0 0;color:var(--muted);font-size:1.0rem;max-width:70ch}\n",
       ".tutorial-card{background:var(--panel);padding:16px 18px}\n",
       ".tutorial-card h2{margin:0 0 10px;font-size:1.3rem}\n",
       ".tutorial-card p{margin:0 0 10px;color:var(--muted);font-size:1.0rem;line-height:1.55;text-align:justify}\n",
       ".tutorial-wrap a{color:var(--accent);text-decoration:none;border-bottom:1px dashed rgba(37,99,235,.5)}\n",
       ".tutorial-wrap a:hover{border-bottom-style:solid}\n",
       ".tutorial-wrap code{font-family:ui-monospace,monospace;background:#f1f5f9;border-radius:8px;padding:2px 6px}\n",
       ".logo-box{display:flex;justify-content:center}\n",
       ".logo-box img{width:min(260px,100%);height:auto;filter:drop-shadow(0 10px 22px rgba(0,0,0,.22))}\n",
       "@media (max-width:980px){.hero-section{grid-template-columns:1fr}.logo-box{justify-content:flex-start}}\n",
       "</style>\n",
       "\n",
       "<div class=\"tutorial-wrap\" id=\"tutorialIntro\">\n",
       "  <div class=\"hero-section\">\n",
       "    <div>\n",
       "      <h1 class=\"tutorial-title\">SPARC Tutorial</h1>\n",
       "      <p class=\"tutorial-subtitle\">\n",
       "        A hands-on of <b>SPARC</b> (Smart Potential with Atomistic Rare Events and Continuous Learning):\n",
       "        an automated workflow for constructing machine learning interatomic potentials (MLIPs).\n",
       "      </p>\n",
       "    </div>\n",
       "    <div class=\"logo-box\">\n",
       "      <img src=\"https://raw.githubusercontent.com/rahulumrao/sparc/main/docs/_static/sparc_logo.png\" alt=\"SPARC logo\"/>\n",
       "    </div>\n",
       "  </div>\n",
       "  <div class=\"content-grid\">\n",
       "    <div class=\"tutorial-card\">\n",
       "      <h2>Introduction</h2>\n",
       "      <p>SPARC is a Python package built around the <code>ASE</code> interface and provides a modular workflow for training machine learning interatomic potentials (MLIPs) for reactive and nonreactive systems.</p>\n",
       "      <p>This notebook provides a tutorial for executing the SPARC active learning workflow.</p>\n",
       "      <p>References and project materials:\n",
       "        <a href=\"https://docs-sparc.readthedocs.io/en/latest/\" target=\"_blank\">SPARC documentation</a> ·\n",
       "        <a href=\"https://github.com/rahulumrao/sparc\" target=\"_blank\">GitHub repository</a>\n",
       "      </p>\n",
       "    </div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title SPARC\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(r\"\"\"\n",
    "<style>\n",
    ".tutorial-wrap{--bg:#f6f8fc;--panel:#ffffff;--panel-soft:rgba(255,255,255,.75);--stroke:rgba(16,24,40,.12);--text:#0f172a;--muted:rgba(15,23,42,.7);--accent:#2563eb;--radius:18px;font-family:system-ui,-apple-system,sans-serif;color:var(--text);padding:22px;margin:8px 0 18px;background:radial-gradient(1000px 500px at 15% 10%,rgba(37,99,235,.15),transparent 55%),radial-gradient(800px 450px at 85% 15%,rgba(124,58,237,.12),transparent 50%),var(--bg)}\n",
    ".hero-section{display:grid;grid-template-columns:1.2fr .8fr;gap:18px;align-items:center;padding:18px;border-radius:calc(var(--radius) - 6px);background:linear-gradient(135deg,var(--panel),var(--panel-soft))}\n",
    ".content-grid{margin-top:16px}\n",
    ".tutorial-title{margin:0;font-size:clamp(2.1rem,5vw,3rem);line-height:1.1}\n",
    ".tutorial-subtitle{margin:10px 0 0;color:var(--muted);font-size:1.0rem;max-width:70ch}\n",
    ".tutorial-card{background:var(--panel);padding:16px 18px}\n",
    ".tutorial-card h2{margin:0 0 10px;font-size:1.3rem}\n",
    ".tutorial-card p{margin:0 0 10px;color:var(--muted);font-size:1.0rem;line-height:1.55;text-align:justify}\n",
    ".tutorial-wrap a{color:var(--accent);text-decoration:none;border-bottom:1px dashed rgba(37,99,235,.5)}\n",
    ".tutorial-wrap a:hover{border-bottom-style:solid}\n",
    ".tutorial-wrap code{font-family:ui-monospace,monospace;background:#f1f5f9;border-radius:8px;padding:2px 6px}\n",
    ".logo-box{display:flex;justify-content:center}\n",
    ".logo-box img{width:min(260px,100%);height:auto;filter:drop-shadow(0 10px 22px rgba(0,0,0,.22))}\n",
    "@media (max-width:980px){.hero-section{grid-template-columns:1fr}.logo-box{justify-content:flex-start}}\n",
    "</style>\n",
    "\n",
    "<div class=\"tutorial-wrap\" id=\"tutorialIntro\">\n",
    "  <div class=\"hero-section\">\n",
    "    <div>\n",
    "      <h1 class=\"tutorial-title\">SPARC Tutorial</h1>\n",
    "      <p class=\"tutorial-subtitle\">\n",
    "        A hands-on of <b>SPARC</b> (Smart Potential with Atomistic Rare Events and Continuous Learning):\n",
    "        an automated workflow for constructing machine learning interatomic potentials (MLIPs).\n",
    "      </p>\n",
    "    </div>\n",
    "    <div class=\"logo-box\">\n",
    "      <img src=\"https://raw.githubusercontent.com/rahulumrao/sparc/main/docs/_static/sparc_logo.png\" alt=\"SPARC logo\"/>\n",
    "    </div>\n",
    "  </div>\n",
    "  <div class=\"content-grid\">\n",
    "    <div class=\"tutorial-card\">\n",
    "      <h2>Introduction</h2>\n",
    "      <p>SPARC is a Python package built around the <code>ASE</code> interface and provides a modular workflow for training machine learning interatomic potentials (MLIPs) for reactive and nonreactive systems.</p>\n",
    "      <p>This notebook provides a tutorial for executing the SPARC active learning workflow.</p>\n",
    "      <p>References and project materials:\n",
    "        <a href=\"https://docs-sparc.readthedocs.io/en/latest/\" target=\"_blank\">SPARC documentation</a> ·\n",
    "        <a href=\"https://github.com/rahulumrao/sparc\" target=\"_blank\">GitHub repository</a>\n",
    "      </p>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02eaa77e",
   "metadata": {},
   "source": [
    "#### **Setup and Installation**\n",
    "\n",
    "<!-- !pip install git+https://github.com/rahulumrao/sparc.git -->\n",
    "\n",
    "Create and Initialize `conda` environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9a3551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Locally ==> skipping Colab setup.\n",
      "\n",
      "\u001b[90mCreate a conda environment if needed:\u001b[0m\n",
      "\u001b[94m  conda create -n sparc python=3.10\u001b[0m\n",
      "\u001b[94m  conda activate sparc\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optional: Only required when running in Google Colab.\n",
    "# If you are running this notebook locally, you can skip this cell.\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab  # noqa\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "\n",
    "if in_colab():\n",
    "    try:\n",
    "        import condacolab\n",
    "        print(\" Colab environment detected - condacolab already installed.\")\n",
    "    except ImportError:\n",
    "        print(\" Google Colab environemnt detected ==> installing condacolab...\")\n",
    "        !pip install -q condacolab\n",
    "        import condacolab\n",
    "        condacolab.install()\n",
    "else:\n",
    "    print(\"Running Locally ==> skipping Colab setup.\\n\")\n",
    "    print(\"\\033[90mCreate a conda environment if needed:\\033[0m\")\n",
    "    print(\"\\033[94m  conda create -n sparc python=3.10\\033[0m\")\n",
    "    print(\"\\033[94m  conda activate sparc\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e521973",
   "metadata": {},
   "source": [
    "In this tutorial, we will use [CP2K](https://anaconda.org/conda-forge/cp2k) for first-principles labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19b540d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! conda install conda-forge::cp2k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9492f47",
   "metadata": {},
   "source": [
    "The conda CP2K distribution does not include `cp2k_shell.x` (required by ASE), so we create a symbolic link as a workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1940d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!path=$(which cp2k.ssmp) && ln -sf \"$path\" \"$(dirname \"$path\")/cp2k_shell.ssmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce0e4874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wazel/anaconda3/envs/notebook/bin/cp2k_shell.ssmp\n"
     ]
    }
   ],
   "source": [
    "!which cp2k_shell.ssmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff390b",
   "metadata": {},
   "source": [
    "Install [SPARC](https://github.com/rahulumrao/sparc) and its dependencies ([DeePMD-kit](https://github.com/deepmodeling/deepmd-kit) and [PLUMED](https://www.plumed.org/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/rahulumrao/sparc.git\n",
    "!pip install deepmd-kit[gpu,cu12]==2.2.10\n",
    "!conda install -c conda-forge py-plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc6042ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid a known runtime issue. Not required for local runs.\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import google.colab  # noqa\n",
    "    os.environ[\"MPLBACKEND\"] = \"Agg\"\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a0b10",
   "metadata": {},
   "source": [
    "After installation, verify that SPARC is correctly installed. You should see output similar to the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb99e7",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 0.8em;\">\n",
    "<!-- After installation, verify that SPARC is correctly installed. You should see output similar to the following: -->\n",
    "<span style=\"font-size: 0.8em;\">\n",
    "\n",
    "```text\n",
    "[SPARC][INFO] \n",
    "         ######  ########     ###    ########   ######\n",
    "        ##    ## ##     ##   ## ##   ##     ## ##    ##\n",
    "        ##       ##     ##  ##   ##  ##     ## ##\n",
    "         ######  ########  ##     ## ########  ##\n",
    "              ## ##        ######### ##   ##   ##\n",
    "        ##    ## ##        ##     ## ##    ##  ##    ##\n",
    "         ######  ##        ##     ## ##     ##  ######\n",
    "         --v0.1.0\n",
    "\n",
    "usage: sparc [-h] [-i INPUT_FILE]\n",
    "\n",
    "Run main SPARC workflow\n",
    "\n",
    "options:\n",
    "  -h, --help            show this help message and exit\n",
    "  -i INPUT_FILE, --input_file INPUT_FILE\n",
    "                        Input YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17adaefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress TensorFlow / DeepMD warnings\n",
    "import os, logging\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "logging.getLogger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b543496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "[SPARC][INFO] \n",
      "         ######  ########     ###    ########   ######\n",
      "        ##    ## ##     ##   ## ##   ##     ## ##    ##\n",
      "        ##       ##     ##  ##   ##  ##     ## ##\n",
      "         ######  ########  ##     ## ########  ##\n",
      "              ## ##        ######### ##   ##   ##\n",
      "        ##    ## ##        ##     ## ##    ##  ##    ##\n",
      "         ######  ##        ##     ## ##     ##  ######\n",
      "         --v0.1.0\n",
      "usage: sparc [-h] [-i INPUT_FILE]\n",
      "\n",
      "Run main SPARC workflow\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i INPUT_FILE, --input_file INPUT_FILE\n",
      "                        Input YAML file\n"
     ]
    }
   ],
   "source": [
    "!sparc -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4dcf9d",
   "metadata": {},
   "source": [
    "##### Download the training data and input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463f568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mHhjhwJ8s2ttE1MuZHeOTGpA1N3JPML8\n",
      "To: /home/wazel/rahul/sparc/nh3bh3/Notebook/NoteBookData.zip\n",
      "100%|██████████| 20.2k/20.2k [00:00<00:00, 65.3MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NoteBookData.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "\n",
    "file_id = \"1mHhjhwJ8s2ttE1MuZHeOTGpA1N3JPML8\"\n",
    "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f46b1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  NoteBookData.zip\n",
      "   creating: NoteBookData/\n",
      "  inflating: NoteBookData/input.json  \n",
      "  inflating: NoteBookData/input.yaml  \n",
      "  inflating: NoteBookData/README.md  \n",
      "  inflating: NoteBookData/cp2k_template.inp  \n",
      "  inflating: NoteBookData/plumed_dp.dat  \n",
      "  inflating: NoteBookData/AmmoniaBorate.xyz  \n",
      "   creating: NoteBookData/iter_000000/\n",
      "   creating: NoteBookData/iter_000000/00.dft/\n",
      "  inflating: NoteBookData/iter_000000/00.dft/AseMD.traj  \n"
     ]
    }
   ],
   "source": [
    "!unzip NoteBookData.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f270fba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wazel/rahul/sparc/nh3bh3/Notebook/NoteBookData\n"
     ]
    }
   ],
   "source": [
    "%cd NoteBookData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcdfdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmmoniaBorate.xyz  input.json  iter_000000    README.md\n",
      "cp2k_template.inp  input.yaml  plumed_dp.dat\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5e913",
   "metadata": {},
   "source": [
    "#### Dataset contents\n",
    "\n",
    "The downloaded archive contains the following files:\n",
    "\n",
    "- **AmmoniaBorate.xyz** — Initial atomic structure in XYZ format used to start the simulation.\n",
    "- **cp2k_template.inp** — Template CP2K input file for first-principles labeling.\n",
    "- **input.yaml** — Main SPARC configuration file defining the workflow and parameters.\n",
    "- **input.json** — DeePMD training configuration file.\n",
    "- **plumed_dp.dat** — PLUMED input file to accelerate ML/MD exploration.\n",
    "- **iter_000000/** — Initial iteration directory containing seed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8984086",
   "metadata": {},
   "source": [
    "##### Configure the CP2K data directory\n",
    "\n",
    "CP2K requires access to basis sets and pseudopotentials via the `CP2K_DATA_DIR` environment variable.  \n",
    "To ensure portability across local, Colab, and conda environments, we automatically detect the CP2K installation path and set the data directory accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef847c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP2K_DATA_DIR = /home/wazel/anaconda3/envs/notebook/share/cp2k/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "cp2k_path = subprocess.check_output([\"which\", \"cp2k.ssmp\"], text=True).strip()\n",
    "cp2k_root = Path(cp2k_path).resolve().parent.parent\n",
    "data_dir = cp2k_root / \"share\" / \"cp2k\" / \"data\"\n",
    "\n",
    "os.environ[\"CP2K_DATA_DIR\"] = str(data_dir)\n",
    "\n",
    "print(\"CP2K_DATA_DIR =\", os.environ[\"CP2K_DATA_DIR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d19fe3",
   "metadata": {},
   "source": [
    "The CP2K executable may be installed in different locations depending on the system. We therefore need to update the `exe_command` entry in `input.yaml` with the correct path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a46f830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!p=$(which cp2k_shell.ssmp); sed -i \"s|^[[:space:]]*exe_command:.*|  exe_command: \\\"env OMP_NUM_THREADS=4 $p\\\"|\" input.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2c71e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wazel/anaconda3/envs/notebook/bin/cp2k.ssmp'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp2k_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762015da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-20 14:19:22.695336: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:19:22.732151: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:19:23.230709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "[SPARC][INFO] \n",
      "         ######  ########     ###    ########   ######\n",
      "        ##    ## ##     ##   ## ##   ##     ## ##    ##\n",
      "        ##       ##     ##  ##   ##  ##     ## ##\n",
      "         ######  ########  ##     ## ########  ##\n",
      "              ## ##        ######### ##   ##   ##\n",
      "        ##    ## ##        ##     ## ##    ##  ##    ##\n",
      "         ######  ##        ##     ## ##     ##  ######\n",
      "         --v0.1.0\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]   Input Configurations (- PLEASE CHECK SPARC INPUTS CAREFULLY! -)\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] active_learning: true\n",
      "deepmd_setup:\n",
      "  MdSimulation: true\n",
      "  data_dir: DeePMD_training/00.data\n",
      "  input_file: input.json\n",
      "  log_frequency: 40\n",
      "  md_steps: 1000\n",
      "  multiple_run: 1\n",
      "  num_models: 2\n",
      "  plumed_file: plumed_dp.dat\n",
      "  skip_max: null\n",
      "  skip_min: 0\n",
      "  timestep_fs: 1.0\n",
      "  training: true\n",
      "  use_plumed: true\n",
      "dft_calculator:\n",
      "  exe_command: env OMP_NUM_THREADS=4 /home/wazel/anaconda3/envs/notebook/bin/cp2k_shell.ssmp\n",
      "  name: CP2K\n",
      "  template_file: cp2k_template.inp\n",
      "general:\n",
      "  structure_file: AmmoniaBorate.xyz\n",
      "iteration: 1\n",
      "latest_model: iter_000009/01.train/training_1/frozen_model_1.pb\n",
      "learning_restart: false\n",
      "md_simulation:\n",
      "  ensemble: NVT\n",
      "  log_frequency: 5\n",
      "  restart: false\n",
      "  steps: 0\n",
      "  tdamp: 25\n",
      "  temperature: 300\n",
      "  thermostat: Nose\n",
      "  timestep_fs: 1.0\n",
      "  use_dft_plumed: false\n",
      "model_dev:\n",
      "  f_max_dev: 0.3\n",
      "  f_min_dev: 0.05\n",
      "output:\n",
      "  aimdtraj_file: AseMD.traj\n",
      "  dptraj_file: dpmd.traj\n",
      "  log_file: AseMD.log\n",
      "  xyz_file: AseTraj.xyz\n",
      "[SPARC][INFO] \n",
      "YAML configuration loaded successfully!\n",
      "[SPARC][INFO] STRUCTURE FILE: Atoms(symbols='BH6N', pbc=True, cell=[12.0, 12.0, 12.0])\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] Creating directories for Iteration: 000000\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] ├── iter_000000/\n",
      "[SPARC][INFO] │   ├── 00.dft/\n",
      "[SPARC][INFO] │   ├── 01.train/\n",
      "[SPARC][INFO] │   └── 02.dpmd/\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] # The /home/wazel/rahul/sparc/nh3bh3/Notebook/NoteBookData/DeePMD_training/00.data/training data contains 51 frames\n",
      "[SPARC][INFO] # The /home/wazel/rahul/sparc/nh3bh3/Notebook/NoteBookData/DeePMD_training/00.data/validation data contains 13 frames\n",
      "[SPARC][INFO] Original directory: /home/wazel/rahul/sparc/nh3bh3/Notebook/NoteBookData\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]           DEEPMD WILL TRAIN 2 MODELS !\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]   RUNNING TRAINING IN FOLDER (iter_000000/01.train/training_1) !\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] Creating new training folder: iter_000000/01.train/training_1\n",
      "2026-02-20 14:19:23.932597: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:19:23.965932: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:19:24.394287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "WARNING:deepmd.train.run_options:Switch to serial execution due to lack of horovod module.\n",
      "DEEPMD INFO    Calculate neighbor statistics... (add --skip-neighbor-stat to skip this step)\n",
      "2026-02-20 14:19:27.196304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:19:27.197722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:19:27.202596: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:19:27.273859: I tensorflow/core/util/cuda_solvers.cc:178] Creating GpuSolver handles for stream 0x59d6ebb6c8f0\n",
      "DEEPMD INFO    training data with min nbor dist: 1.0205944346311124\n",
      "DEEPMD INFO    training data with max nbor size: [1 6 1]\n",
      "DEEPMD INFO     _____               _____   __  __  _____           _     _  _   \n",
      "DEEPMD INFO    |  __ \\             |  __ \\ |  \\/  ||  __ \\         | |   (_)| |  \n",
      "DEEPMD INFO    | |  | |  ___   ___ | |__) || \\  / || |  | | ______ | | __ _ | |_ \n",
      "DEEPMD INFO    | |  | | / _ \\ / _ \\|  ___/ | |\\/| || |  | ||______|| |/ /| || __|\n",
      "DEEPMD INFO    | |__| ||  __/|  __/| |     | |  | || |__| |        |   < | || |_ \n",
      "DEEPMD INFO    |_____/  \\___| \\___||_|     |_|  |_||_____/         |_|\\_\\|_| \\__|\n",
      "DEEPMD INFO    Please read and cite:\n",
      "DEEPMD INFO    Wang, Zhang, Han and E, Comput.Phys.Comm. 228, 178-184 (2018)\n",
      "DEEPMD INFO    Zeng et al, J. Chem. Phys., 159, 054801 (2023)\n",
      "DEEPMD INFO    See https://deepmd.rtfd.io/credits/ for details.\n",
      "DEEPMD INFO    installed to:         /usr/local\n",
      "DEEPMD INFO    source :              v2.2.10\n",
      "DEEPMD INFO    source brach:         HEAD\n",
      "DEEPMD INFO    source commit:        f8a0b312\n",
      "DEEPMD INFO    source commit at:     2024-04-06 14:46:23 -0400\n",
      "DEEPMD INFO    build float prec:     double\n",
      "DEEPMD INFO    build variant:        cuda\n",
      "DEEPMD INFO    build with tf inc:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/;/tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/\n",
      "DEEPMD INFO    build with tf lib:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/libtensorflow_cc.so.2\n",
      "DEEPMD INFO    ---Summary of the training---------------------------------------\n",
      "DEEPMD INFO    running on:           cbe-dt-350.che.ncsu.edu\n",
      "DEEPMD INFO    computing device:     cpu:0\n",
      "DEEPMD INFO    CUDA_VISIBLE_DEVICES: unset\n",
      "DEEPMD INFO    Count of visible GPU: 0\n",
      "DEEPMD INFO    num_intra_threads:    0\n",
      "DEEPMD INFO    num_inter_threads:    0\n",
      "DEEPMD INFO    -----------------------------------------------------------------\n",
      "2026-02-20 14:19:28.192347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:19:28.193341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    training without frame parameter\n",
      "DEEPMD INFO    data stating... (this step may take long time)\n",
      "DEEPMD INFO    built lr\n",
      "DEEPMD INFO    built network\n",
      "DEEPMD INFO    built training\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:19:29.250780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:19:29.251723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    initialize model from scratch\n",
      "DEEPMD INFO    start training at lr 1.00e-03 (== 1.00e-03), decay_step 5000, decay_rate 0.076971, final lr will be 3.51e-08\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/train/trainer.py:1194: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/train/trainer.py:1194: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "2026-02-20 14:19:30.762125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:19:30.763038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    batch     100 training time 1.52 s, testing time 0.01 s, total wall time 1.99 s\n",
      "DEEPMD INFO    batch     200 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch     300 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch     400 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch     500 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch     600 training time 0.87 s, testing time 0.02 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch     700 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch     800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch     900 training time 0.86 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    1000 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    1100 training time 0.83 s, testing time 0.02 s, total wall time 1.00 s\n",
      "DEEPMD INFO    batch    1200 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    1300 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    1400 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    1500 training time 0.88 s, testing time 0.02 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    1600 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    1700 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    1800 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    1900 training time 0.86 s, testing time 0.02 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    2000 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    2100 training time 0.85 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch    2200 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    2300 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    2400 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    2500 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    2600 training time 0.86 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    2700 training time 0.86 s, testing time 0.02 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    2800 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    2900 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    3000 training time 0.86 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    3100 training time 0.84 s, testing time 0.02 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch    3200 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    3300 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    3400 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    3500 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    3600 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    3700 training time 0.83 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    3800 training time 0.87 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    3900 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    4000 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    4100 training time 0.86 s, testing time 0.01 s, total wall time 0.96 s\n",
      "DEEPMD INFO    batch    4200 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    4300 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    4400 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    4500 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    4600 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    4700 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    4800 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    4900 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    5000 training time 0.86 s, testing time 0.02 s, total wall time 0.89 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    5100 training time 0.85 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch    5200 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    5300 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    5400 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    5500 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    5600 training time 0.87 s, testing time 0.02 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    5700 training time 0.85 s, testing time 0.02 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    5800 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    5900 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    6000 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    6100 training time 0.86 s, testing time 0.01 s, total wall time 0.96 s\n",
      "DEEPMD INFO    batch    6200 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    6300 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    6400 training time 0.88 s, testing time 0.02 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    6500 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    6600 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch    6700 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    6800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    6900 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    7000 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    7100 training time 0.84 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch    7200 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    7300 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    7400 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    7500 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    7600 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    7700 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    7800 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    7900 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    8000 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    8100 training time 0.84 s, testing time 0.01 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch    8200 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    8300 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    8400 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    8500 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    8600 training time 0.84 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    8700 training time 0.84 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    8800 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    8900 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    9000 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    9100 training time 0.82 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch    9200 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    9300 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    9400 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    9500 training time 0.87 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    9600 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    9700 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    9800 training time 0.88 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    9900 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   10000 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   10100 training time 0.85 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch   10200 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   10300 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   10400 training time 0.86 s, testing time 0.02 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   10500 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   10600 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   10700 training time 0.85 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   10800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   10900 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   11000 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   11100 training time 0.86 s, testing time 0.01 s, total wall time 0.97 s\n",
      "DEEPMD INFO    batch   11200 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   11300 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   11400 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   11500 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   11600 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   11700 training time 0.87 s, testing time 0.02 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   11800 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   11900 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   12000 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   12100 training time 0.84 s, testing time 0.02 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch   12200 training time 0.89 s, testing time 0.01 s, total wall time 0.92 s\n",
      "DEEPMD INFO    batch   12300 training time 0.89 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch   12400 training time 0.88 s, testing time 0.01 s, total wall time 0.92 s\n",
      "DEEPMD INFO    batch   12500 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   12600 training time 0.86 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   12700 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   12800 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   12900 training time 0.90 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch   13000 training time 0.92 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   13100 training time 0.87 s, testing time 0.01 s, total wall time 0.97 s\n",
      "DEEPMD INFO    batch   13200 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   13300 training time 0.85 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   13400 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   13500 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   13600 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   13700 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   13800 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   13900 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   14000 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   14100 training time 0.86 s, testing time 0.01 s, total wall time 0.97 s\n",
      "DEEPMD INFO    batch   14200 training time 0.89 s, testing time 0.01 s, total wall time 0.92 s\n",
      "DEEPMD INFO    batch   14300 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   14400 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   14500 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   14600 training time 0.90 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch   14700 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   14800 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   14900 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   15000 training time 0.89 s, testing time 0.01 s, total wall time 0.92 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   15100 training time 0.86 s, testing time 0.02 s, total wall time 0.97 s\n",
      "DEEPMD INFO    batch   15200 training time 0.89 s, testing time 0.01 s, total wall time 0.92 s\n",
      "DEEPMD INFO    batch   15300 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   15400 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   15500 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   15600 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   15700 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   15800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   15900 training time 0.82 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   16000 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   16100 training time 0.87 s, testing time 0.02 s, total wall time 0.98 s\n",
      "DEEPMD INFO    batch   16200 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   16300 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   16400 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   16500 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   16600 training time 0.86 s, testing time 0.02 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   16700 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   16800 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   16900 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   17000 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   17100 training time 0.85 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch   17200 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   17300 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   17400 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   17500 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   17600 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   17700 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   17800 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   17900 training time 0.88 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   18000 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   18100 training time 0.84 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch   18200 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   18300 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   18400 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   18500 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   18600 training time 0.90 s, testing time 0.02 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch   18700 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   18800 training time 0.87 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   18900 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   19000 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   19100 training time 0.85 s, testing time 0.01 s, total wall time 0.96 s\n",
      "DEEPMD INFO    batch   19200 training time 0.84 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   19300 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   19400 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   19500 training time 0.88 s, testing time 0.02 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   19600 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   19700 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   19800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   19900 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   20000 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    average training time: 0.0085 s/batch (exclude first 100 batches)\n",
      "DEEPMD INFO    finished training\n",
      "DEEPMD INFO    wall time: 179.842 s\n",
      "2026-02-20 14:22:29.988703: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:22:30.023866: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:22:30.451120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:22:31.585645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:31.586908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:31.627137: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "DEEPMD WARNING The following nodes are not in the graph: {'fitting_attr/aparam_nall', 'spin_attr/ntypes_spin'}. Skip freezeing these nodes. You may be freezing a checkpoint generated by an old version.\n",
      "DEEPMD INFO    The following nodes will be frozen: ['o_virial', 'train_attr/min_nbor_dist', 'descrpt_attr/rcut', 'model_attr/tmap', 'model_attr/model_version', 'fitting_attr/daparam', 'o_atom_energy', 'descrpt_attr/ntypes', 'model_type', 'train_attr/training_script', 't_mesh', 'o_force', 'model_attr/model_type', 'o_energy', 'o_atom_virial', 'fitting_attr/dfparam']\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "DEEPMD INFO    1046 ops in the final graph.\n",
      "2026-02-20 14:22:32.951550: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:22:32.986362: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:22:33.424602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:22:34.305848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:34.307175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:34.322477: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:22:34.353271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:34.354186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:34.579836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:34.580747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    \n",
      "\n",
      "\n",
      "DEEPMD INFO    stage 1: compress the model\n",
      "DEEPMD WARNING Switch to serial execution due to lack of horovod module.\n",
      "DEEPMD INFO     _____               _____   __  __  _____           _     _  _   \n",
      "DEEPMD INFO    |  __ \\             |  __ \\ |  \\/  ||  __ \\         | |   (_)| |  \n",
      "DEEPMD INFO    | |  | |  ___   ___ | |__) || \\  / || |  | | ______ | | __ _ | |_ \n",
      "DEEPMD INFO    | |  | | / _ \\ / _ \\|  ___/ | |\\/| || |  | ||______|| |/ /| || __|\n",
      "DEEPMD INFO    | |__| ||  __/|  __/| |     | |  | || |__| |        |   < | || |_ \n",
      "DEEPMD INFO    |_____/  \\___| \\___||_|     |_|  |_||_____/         |_|\\_\\|_| \\__|\n",
      "DEEPMD INFO    Please read and cite:\n",
      "DEEPMD INFO    Wang, Zhang, Han and E, Comput.Phys.Comm. 228, 178-184 (2018)\n",
      "DEEPMD INFO    Zeng et al, J. Chem. Phys., 159, 054801 (2023)\n",
      "DEEPMD INFO    See https://deepmd.rtfd.io/credits/ for details.\n",
      "DEEPMD INFO    installed to:         /usr/local\n",
      "DEEPMD INFO    source :              v2.2.10\n",
      "DEEPMD INFO    source brach:         HEAD\n",
      "DEEPMD INFO    source commit:        f8a0b312\n",
      "DEEPMD INFO    source commit at:     2024-04-06 14:46:23 -0400\n",
      "DEEPMD INFO    build float prec:     double\n",
      "DEEPMD INFO    build variant:        cuda\n",
      "DEEPMD INFO    build with tf inc:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/;/tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/\n",
      "DEEPMD INFO    build with tf lib:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/libtensorflow_cc.so.2\n",
      "DEEPMD INFO    ---Summary of the training---------------------------------------\n",
      "DEEPMD INFO    running on:           cbe-dt-350.che.ncsu.edu\n",
      "DEEPMD INFO    computing device:     cpu:0\n",
      "DEEPMD INFO    CUDA_VISIBLE_DEVICES: unset\n",
      "DEEPMD INFO    Count of visible GPU: 0\n",
      "DEEPMD INFO    num_intra_threads:    0\n",
      "DEEPMD INFO    num_inter_threads:    0\n",
      "DEEPMD INFO    -----------------------------------------------------------------\n",
      "2026-02-20 14:22:36.371893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.372789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    training without frame parameter\n",
      "2026-02-20 14:22:36.423008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.423922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.432105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.433007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.459021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.459933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.485062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.485983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    training data with lower boundary: [-0.60005722 -0.55589506 -0.59445131]\n",
      "DEEPMD INFO    training data with upper boundary: [2.51072235 3.26385169 2.02921262]\n",
      "2026-02-20 14:22:36.693807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.694723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.721632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.722535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.751335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:36.752249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    built lr\n",
      "DEEPMD INFO    built network\n",
      "DEEPMD INFO    built training\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:22:37.411253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:37.412159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    initialize model from scratch\n",
      "DEEPMD INFO    finished compressing\n",
      "DEEPMD INFO    \n",
      "\n",
      "\n",
      "DEEPMD INFO    stage 2: freeze the model\n",
      "2026-02-20 14:22:37.884227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:37.885178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD WARNING The following nodes are not in the graph: {'spin_attr/ntypes_spin', 'fitting_attr/aparam_nall'}. Skip freezeing these nodes. You may be freezing a checkpoint generated by an old version.\n",
      "DEEPMD INFO    The following nodes will be frozen: ['o_force', 'descrpt_attr/ntypes', 'fitting_attr/daparam', 'fitting_attr/dfparam', 'descrpt_attr/rcut', 'train_attr/min_nbor_dist', 'model_type', 'model_attr/model_type', 'train_attr/training_script', 'model_attr/model_version', 't_mesh', 'o_atom_virial', 'model_attr/tmap', 'o_energy', 'o_atom_energy', 'o_virial']\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "DEEPMD INFO    778 ops in the final graph.\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] DeepMD Model Evaluation Results\n",
      "[SPARC][INFO] ------------------------------------------------------------------------\n",
      "[SPARC][INFO] 2026-02-20 14:22:38.961112: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:22:38.995017: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:22:39.430684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:22:40.308578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:40.309924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:40.325835: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:22:40.398973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:40.399886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    # ---------------output of dp test--------------- \n",
      "DEEPMD INFO    # testing system : /home/wazel/rahul/sparc/nh3bh3/Notebook/NoteBookData/DeePMD_training/00.data/validation_data\n",
      "DEEPMD INFO    # number of test data : 13 \n",
      "DEEPMD INFO    Energy MAE         : 2.754948e-02 eV\n",
      "DEEPMD INFO    Energy RMSE        : 3.049580e-02 eV\n",
      "DEEPMD INFO    Energy MAE/Natoms  : 3.443685e-03 eV\n",
      "DEEPMD INFO    Energy RMSE/Natoms : 3.811975e-03 eV\n",
      "DEEPMD INFO    Force  MAE         : 3.381560e-02 eV/A\n",
      "DEEPMD INFO    Force  RMSE        : 1.331805e-01 eV/A\n",
      "DEEPMD INFO    Virial MAE         : 1.797967e-01 eV\n",
      "DEEPMD INFO    Virial RMSE        : 4.712356e-01 eV\n",
      "DEEPMD INFO    Virial MAE/Natoms  : 2.247459e-02 eV\n",
      "DEEPMD INFO    Virial RMSE/Natoms : 5.890445e-02 eV\n",
      "DEEPMD INFO    # -----------------------------------------------\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]   RUNNING TRAINING IN FOLDER (iter_000000/01.train/training_2) !\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] Creating new training folder: iter_000000/01.train/training_2\n",
      "2026-02-20 14:22:41.497257: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:22:41.532150: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:22:41.958691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "WARNING:deepmd.train.run_options:Switch to serial execution due to lack of horovod module.\n",
      "DEEPMD INFO    Calculate neighbor statistics... (add --skip-neighbor-stat to skip this step)\n",
      "2026-02-20 14:22:44.759931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:44.761236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:44.766085: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:22:44.841935: I tensorflow/core/util/cuda_solvers.cc:178] Creating GpuSolver handles for stream 0x649c6b6b7870\n",
      "DEEPMD INFO    training data with min nbor dist: 1.0205944346311124\n",
      "DEEPMD INFO    training data with max nbor size: [1 6 1]\n",
      "DEEPMD INFO     _____               _____   __  __  _____           _     _  _   \n",
      "DEEPMD INFO    |  __ \\             |  __ \\ |  \\/  ||  __ \\         | |   (_)| |  \n",
      "DEEPMD INFO    | |  | |  ___   ___ | |__) || \\  / || |  | | ______ | | __ _ | |_ \n",
      "DEEPMD INFO    | |  | | / _ \\ / _ \\|  ___/ | |\\/| || |  | ||______|| |/ /| || __|\n",
      "DEEPMD INFO    | |__| ||  __/|  __/| |     | |  | || |__| |        |   < | || |_ \n",
      "DEEPMD INFO    |_____/  \\___| \\___||_|     |_|  |_||_____/         |_|\\_\\|_| \\__|\n",
      "DEEPMD INFO    Please read and cite:\n",
      "DEEPMD INFO    Wang, Zhang, Han and E, Comput.Phys.Comm. 228, 178-184 (2018)\n",
      "DEEPMD INFO    Zeng et al, J. Chem. Phys., 159, 054801 (2023)\n",
      "DEEPMD INFO    See https://deepmd.rtfd.io/credits/ for details.\n",
      "DEEPMD INFO    installed to:         /usr/local\n",
      "DEEPMD INFO    source :              v2.2.10\n",
      "DEEPMD INFO    source brach:         HEAD\n",
      "DEEPMD INFO    source commit:        f8a0b312\n",
      "DEEPMD INFO    source commit at:     2024-04-06 14:46:23 -0400\n",
      "DEEPMD INFO    build float prec:     double\n",
      "DEEPMD INFO    build variant:        cuda\n",
      "DEEPMD INFO    build with tf inc:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/;/tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/\n",
      "DEEPMD INFO    build with tf lib:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/libtensorflow_cc.so.2\n",
      "DEEPMD INFO    ---Summary of the training---------------------------------------\n",
      "DEEPMD INFO    running on:           cbe-dt-350.che.ncsu.edu\n",
      "DEEPMD INFO    computing device:     cpu:0\n",
      "DEEPMD INFO    CUDA_VISIBLE_DEVICES: unset\n",
      "DEEPMD INFO    Count of visible GPU: 0\n",
      "DEEPMD INFO    num_intra_threads:    0\n",
      "DEEPMD INFO    num_inter_threads:    0\n",
      "DEEPMD INFO    -----------------------------------------------------------------\n",
      "2026-02-20 14:22:45.744901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:45.745789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    training without frame parameter\n",
      "DEEPMD INFO    data stating... (this step may take long time)\n",
      "DEEPMD INFO    built lr\n",
      "DEEPMD INFO    built network\n",
      "DEEPMD INFO    built training\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:22:46.765929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:46.766811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    initialize model from scratch\n",
      "DEEPMD INFO    start training at lr 1.00e-03 (== 1.00e-03), decay_step 5000, decay_rate 0.076971, final lr will be 3.51e-08\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/train/trainer.py:1194: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/train/trainer.py:1194: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "2026-02-20 14:22:48.274856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:22:48.275767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    batch     100 training time 1.53 s, testing time 0.01 s, total wall time 2.04 s\n",
      "DEEPMD INFO    batch     200 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch     300 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch     400 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch     500 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch     600 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch     700 training time 0.84 s, testing time 0.02 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch     800 training time 0.83 s, testing time 0.02 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch     900 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    1000 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    1100 training time 0.82 s, testing time 0.01 s, total wall time 0.99 s\n",
      "DEEPMD INFO    batch    1200 training time 0.82 s, testing time 0.02 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    1300 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    1400 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    1500 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch    1600 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    1700 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    1800 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch    1900 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    2000 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    2100 training time 0.83 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch    2200 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    2300 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch    2400 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    2500 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    2600 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    2700 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    2800 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    2900 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    3000 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    3100 training time 0.81 s, testing time 0.02 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    3200 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    3300 training time 0.87 s, testing time 0.02 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    3400 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    3500 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    3600 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch    3700 training time 0.82 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch    3800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    3900 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    4000 training time 0.83 s, testing time 0.02 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    4100 training time 0.81 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    4200 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    4300 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch    4400 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    4500 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    4600 training time 0.82 s, testing time 0.02 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    4700 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    4800 training time 0.82 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch    4900 training time 0.82 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    5000 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    5100 training time 0.84 s, testing time 0.01 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch    5200 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    5300 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    5400 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    5500 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    5600 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    5700 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    5800 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    5900 training time 0.85 s, testing time 0.02 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    6000 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    6100 training time 0.83 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch    6200 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    6300 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    6400 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    6500 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    6600 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    6700 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    6800 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    6900 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    7000 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    7100 training time 0.81 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch    7200 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    7300 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    7400 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    7500 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch    7600 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    7700 training time 0.81 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch    7800 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    7900 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    8000 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    8100 training time 0.84 s, testing time 0.01 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch    8200 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch    8300 training time 0.82 s, testing time 0.02 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    8400 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    8500 training time 0.83 s, testing time 0.02 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    8600 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    8700 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    8800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    8900 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    9000 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch    9100 training time 0.85 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch    9200 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    9300 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch    9400 training time 0.86 s, testing time 0.02 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch    9500 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch    9600 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    9700 training time 0.84 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch    9800 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch    9900 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   10000 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   10100 training time 0.84 s, testing time 0.01 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch   10200 training time 0.79 s, testing time 0.02 s, total wall time 0.82 s\n",
      "DEEPMD INFO    batch   10300 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   10400 training time 0.81 s, testing time 0.02 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   10500 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   10600 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   10700 training time 0.86 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    batch   10800 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   10900 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   11000 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   11100 training time 0.83 s, testing time 0.01 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch   11200 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   11300 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   11400 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   11500 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   11600 training time 0.85 s, testing time 0.02 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   11700 training time 0.82 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   11800 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   11900 training time 0.84 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   12000 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   12100 training time 0.82 s, testing time 0.02 s, total wall time 0.92 s\n",
      "DEEPMD INFO    batch   12200 training time 0.82 s, testing time 0.02 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   12300 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   12400 training time 0.81 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   12500 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   12600 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   12700 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   12800 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   12900 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   13000 training time 0.82 s, testing time 0.02 s, total wall time 0.85 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   13100 training time 0.83 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch   13200 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   13300 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   13400 training time 0.84 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   13500 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   13600 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   13700 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   13800 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   13900 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   14000 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   14100 training time 0.83 s, testing time 0.01 s, total wall time 0.94 s\n",
      "DEEPMD INFO    batch   14200 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   14300 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   14400 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   14500 training time 0.81 s, testing time 0.02 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   14600 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   14700 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   14800 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   14900 training time 0.79 s, testing time 0.01 s, total wall time 0.82 s\n",
      "DEEPMD INFO    batch   15000 training time 0.84 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   15100 training time 0.85 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch   15200 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   15300 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   15400 training time 0.82 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   15500 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   15600 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   15700 training time 0.82 s, testing time 0.02 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   15800 training time 0.85 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   15900 training time 0.81 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   16000 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   16100 training time 0.83 s, testing time 0.01 s, total wall time 0.93 s\n",
      "DEEPMD INFO    batch   16200 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   16300 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   16400 training time 0.82 s, testing time 0.02 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   16500 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   16600 training time 0.80 s, testing time 0.02 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   16700 training time 0.84 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   16800 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   16900 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   17000 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   17100 training time 0.81 s, testing time 0.01 s, total wall time 0.91 s\n",
      "DEEPMD INFO    batch   17200 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   17300 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   17400 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   17500 training time 0.84 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   17600 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   17700 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   17800 training time 0.83 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   17900 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   18000 training time 0.87 s, testing time 0.02 s, total wall time 0.90 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   18100 training time 0.85 s, testing time 0.02 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch   18200 training time 0.87 s, testing time 0.01 s, total wall time 0.90 s\n",
      "DEEPMD INFO    batch   18300 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   18400 training time 0.80 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   18500 training time 0.83 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   18600 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   18700 training time 0.81 s, testing time 0.01 s, total wall time 0.83 s\n",
      "DEEPMD INFO    batch   18800 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   18900 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   19000 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    batch   19100 training time 0.85 s, testing time 0.01 s, total wall time 0.95 s\n",
      "DEEPMD INFO    batch   19200 training time 0.81 s, testing time 0.01 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   19300 training time 0.85 s, testing time 0.01 s, total wall time 0.88 s\n",
      "DEEPMD INFO    batch   19400 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   19500 training time 0.83 s, testing time 0.02 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   19600 training time 0.81 s, testing time 0.02 s, total wall time 0.84 s\n",
      "DEEPMD INFO    batch   19700 training time 0.84 s, testing time 0.01 s, total wall time 0.87 s\n",
      "DEEPMD INFO    batch   19800 training time 0.82 s, testing time 0.01 s, total wall time 0.85 s\n",
      "DEEPMD INFO    batch   19900 training time 0.83 s, testing time 0.01 s, total wall time 0.86 s\n",
      "DEEPMD INFO    batch   20000 training time 0.85 s, testing time 0.01 s, total wall time 0.89 s\n",
      "DEEPMD INFO    saved checkpoint model.ckpt\n",
      "DEEPMD INFO    average training time: 0.0083 s/batch (exclude first 100 batches)\n",
      "DEEPMD INFO    finished training\n",
      "DEEPMD INFO    wall time: 174.825 s\n",
      "2026-02-20 14:25:42.466898: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:25:42.501613: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:25:42.941811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:25:44.025436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:44.026656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:44.067268: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "DEEPMD WARNING The following nodes are not in the graph: {'fitting_attr/aparam_nall', 'spin_attr/ntypes_spin'}. Skip freezeing these nodes. You may be freezing a checkpoint generated by an old version.\n",
      "DEEPMD INFO    The following nodes will be frozen: ['o_virial', 'o_energy', 'model_attr/tmap', 'descrpt_attr/rcut', 'fitting_attr/dfparam', 'o_force', 'descrpt_attr/ntypes', 'fitting_attr/daparam', 'model_attr/model_type', 'model_type', 'model_attr/model_version', 'o_atom_virial', 'train_attr/training_script', 't_mesh', 'o_atom_energy', 'train_attr/min_nbor_dist']\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "DEEPMD INFO    1046 ops in the final graph.\n",
      "2026-02-20 14:25:45.418226: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:25:45.452367: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:25:45.879536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:25:46.781631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:46.782980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:46.798891: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:25:46.827064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:46.827951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:47.057218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:47.058126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    \n",
      "\n",
      "\n",
      "DEEPMD INFO    stage 1: compress the model\n",
      "DEEPMD WARNING Switch to serial execution due to lack of horovod module.\n",
      "DEEPMD INFO     _____               _____   __  __  _____           _     _  _   \n",
      "DEEPMD INFO    |  __ \\             |  __ \\ |  \\/  ||  __ \\         | |   (_)| |  \n",
      "DEEPMD INFO    | |  | |  ___   ___ | |__) || \\  / || |  | | ______ | | __ _ | |_ \n",
      "DEEPMD INFO    | |  | | / _ \\ / _ \\|  ___/ | |\\/| || |  | ||______|| |/ /| || __|\n",
      "DEEPMD INFO    | |__| ||  __/|  __/| |     | |  | || |__| |        |   < | || |_ \n",
      "DEEPMD INFO    |_____/  \\___| \\___||_|     |_|  |_||_____/         |_|\\_\\|_| \\__|\n",
      "DEEPMD INFO    Please read and cite:\n",
      "DEEPMD INFO    Wang, Zhang, Han and E, Comput.Phys.Comm. 228, 178-184 (2018)\n",
      "DEEPMD INFO    Zeng et al, J. Chem. Phys., 159, 054801 (2023)\n",
      "DEEPMD INFO    See https://deepmd.rtfd.io/credits/ for details.\n",
      "DEEPMD INFO    installed to:         /usr/local\n",
      "DEEPMD INFO    source :              v2.2.10\n",
      "DEEPMD INFO    source brach:         HEAD\n",
      "DEEPMD INFO    source commit:        f8a0b312\n",
      "DEEPMD INFO    source commit at:     2024-04-06 14:46:23 -0400\n",
      "DEEPMD INFO    build float prec:     double\n",
      "DEEPMD INFO    build variant:        cuda\n",
      "DEEPMD INFO    build with tf inc:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/;/tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/include/\n",
      "DEEPMD INFO    build with tf lib:    /tmp/pip-build-env-uux7fz_s/normal/lib/python3.11/site-packages/tensorflow/libtensorflow_cc.so.2\n",
      "DEEPMD INFO    ---Summary of the training---------------------------------------\n",
      "DEEPMD INFO    running on:           cbe-dt-350.che.ncsu.edu\n",
      "DEEPMD INFO    computing device:     cpu:0\n",
      "DEEPMD INFO    CUDA_VISIBLE_DEVICES: unset\n",
      "DEEPMD INFO    Count of visible GPU: 0\n",
      "DEEPMD INFO    num_intra_threads:    0\n",
      "DEEPMD INFO    num_inter_threads:    0\n",
      "DEEPMD INFO    -----------------------------------------------------------------\n",
      "2026-02-20 14:25:48.857047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.857958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    training without frame parameter\n",
      "2026-02-20 14:25:48.910390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.911285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.919510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.920407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.948899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.949805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.977867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:48.978770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    training data with lower boundary: [-0.60886258 -0.56333917 -0.60145381]\n",
      "DEEPMD INFO    training data with upper boundary: [2.49325419 3.25053746 2.01791628]\n",
      "2026-02-20 14:25:49.243367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:49.244367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:49.275030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:49.275933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:49.309720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:49.310626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    built lr\n",
      "DEEPMD INFO    built network\n",
      "DEEPMD INFO    built training\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:25:50.019096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:50.020010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    initialize model from scratch\n",
      "DEEPMD INFO    finished compressing\n",
      "DEEPMD INFO    \n",
      "\n",
      "\n",
      "DEEPMD INFO    stage 2: freeze the model\n",
      "2026-02-20 14:25:50.502614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:50.503518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD WARNING The following nodes are not in the graph: {'spin_attr/ntypes_spin', 'fitting_attr/aparam_nall'}. Skip freezeing these nodes. You may be freezing a checkpoint generated by an old version.\n",
      "DEEPMD INFO    The following nodes will be frozen: ['model_type', 'o_atom_virial', 'model_attr/model_version', 'fitting_attr/dfparam', 'descrpt_attr/ntypes', 'o_force', 't_mesh', 'o_energy', 'train_attr/training_script', 'model_attr/model_type', 'train_attr/min_nbor_dist', 'o_virial', 'model_attr/tmap', 'o_atom_energy', 'descrpt_attr/rcut', 'fitting_attr/daparam']\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/deepmd/entrypoints/freeze.py:371: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/framework/convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "DEEPMD INFO    778 ops in the final graph.\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] DeepMD Model Evaluation Results\n",
      "[SPARC][INFO] ------------------------------------------------------------------------\n",
      "[SPARC][INFO] 2026-02-20 14:25:51.726435: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:25:51.761192: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:25:52.193503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:25:53.073622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:53.074883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:53.094952: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:25:53.171804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:53.172707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "DEEPMD INFO    # ---------------output of dp test--------------- \n",
      "DEEPMD INFO    # testing system : /home/wazel/rahul/sparc/nh3bh3/Notebook/NoteBookData/DeePMD_training/00.data/validation_data\n",
      "DEEPMD INFO    # number of test data : 13 \n",
      "DEEPMD INFO    Energy MAE         : 1.942276e-02 eV\n",
      "DEEPMD INFO    Energy RMSE        : 2.099769e-02 eV\n",
      "DEEPMD INFO    Energy MAE/Natoms  : 2.427846e-03 eV\n",
      "DEEPMD INFO    Energy RMSE/Natoms : 2.624711e-03 eV\n",
      "DEEPMD INFO    Force  MAE         : 3.352588e-02 eV/A\n",
      "DEEPMD INFO    Force  RMSE        : 1.314991e-01 eV/A\n",
      "DEEPMD INFO    Virial MAE         : 1.729890e-01 eV\n",
      "DEEPMD INFO    Virial RMSE        : 4.701083e-01 eV\n",
      "DEEPMD INFO    Virial MAE/Natoms  : 2.162363e-02 eV\n",
      "DEEPMD INFO    Virial RMSE/Natoms : 5.876353e-02 eV\n",
      "DEEPMD INFO    # -----------------------------------------------\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]       MULTIPLE MLP-MD SIMULATION STARTING FROM SAME CONFIGURATION!\n",
      "[SPARC][INFO] ========================================================================\n",
      "2026-02-20 14:25:54.282876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:54.284216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:54.300241: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:25:54.377754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22212 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:25:54.378670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22353 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] DeepPotential model successfully loaded and tested: \n",
      " iter_000000/01.train/training_1/frozen_model_1.pb\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]     Sim:[0]       PLUMED IS CALLED FOR DPMD SIMULATION !\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] Using PLUMED input file: plumed_dp.dat\n",
      "[SPARC][INFO] PLUMED output files will be written in iter_000000/02.dpmd\n",
      "+++ Loading the PLUMED kernel runtime +++\n",
      "+++ PLUMED_KERNEL=\"/home/wazel/anaconda3/envs/notebook/lib/libplumedKernel.so\" +++\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]             Initializing DeepPotential MD Simulation [Nose]             \n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] Steps: 0, Epot: -441.284473, Ekin: 0.310224, Temp: 300.00\n",
      "[SPARC][INFO] Reference Potential Energy//STEP:0 -> [-441.28530575]\n",
      "[SPARC][INFO] Steps: 40, Epot: -441.753345, Ekin: 0.726177, Temp: 702.24\n",
      "[SPARC][INFO] Steps: 80, Epot: -442.152717, Ekin: 0.644530, Temp: 623.29\n",
      "[SPARC][INFO] Steps: 120, Epot: -442.119562, Ekin: 0.377763, Temp: 365.31\n",
      "[SPARC][INFO] Steps: 160, Epot: -442.062412, Ekin: 0.221577, Temp: 214.27\n",
      "[SPARC][INFO] Steps: 200, Epot: -442.090088, Ekin: 0.210378, Temp: 203.45\n",
      "[SPARC][INFO] Steps: 240, Epot: -442.194398, Ekin: 0.315073, Temp: 304.69\n",
      "[SPARC][INFO] Steps: 280, Epot: -442.326137, Ekin: 0.453785, Temp: 438.83\n",
      "[SPARC][INFO] Steps: 320, Epot: -442.397973, Ekin: 0.432886, Temp: 418.62\n",
      "[SPARC][INFO] Steps: 360, Epot: -442.369824, Ekin: 0.278236, Temp: 269.07\n",
      "[SPARC][INFO] Steps: 400, Epot: -442.320632, Ekin: 0.195375, Temp: 188.94\n",
      "[SPARC][INFO] Steps: 440, Epot: -442.345006, Ekin: 0.247092, Temp: 238.95\n",
      "[SPARC][INFO] Steps: 480, Epot: -442.433022, Ekin: 0.399575, Temp: 386.41\n",
      "[SPARC][INFO] Steps: 520, Epot: -442.477198, Ekin: 0.471831, Temp: 456.28\n",
      "[SPARC][INFO] Steps: 560, Epot: -442.445711, Ekin: 0.337443, Temp: 326.32\n",
      "[SPARC][INFO] Steps: 600, Epot: -442.371876, Ekin: 0.218709, Temp: 211.50\n",
      "[SPARC][INFO] Steps: 640, Epot: -442.291763, Ekin: 0.189579, Temp: 183.33\n",
      "[SPARC][INFO] Steps: 680, Epot: -442.221293, Ekin: 0.222157, Temp: 214.84\n",
      "[SPARC][INFO] Steps: 720, Epot: -442.162535, Ekin: 0.312333, Temp: 302.04\n",
      "[SPARC][INFO] Steps: 760, Epot: -442.100168, Ekin: 0.409131, Temp: 395.65\n",
      "[SPARC][INFO] Steps: 800, Epot: -442.007980, Ekin: 0.422189, Temp: 408.28\n",
      "[SPARC][INFO] Steps: 840, Epot: -441.876457, Ekin: 0.346915, Temp: 335.48\n",
      "[SPARC][INFO] Steps: 880, Epot: -441.723255, Ekin: 0.276067, Temp: 266.97\n",
      "[SPARC][INFO] Steps: 920, Epot: -441.572935, Ekin: 0.265688, Temp: 256.93\n",
      "[SPARC][INFO] Steps: 960, Epot: -441.467247, Ekin: 0.308906, Temp: 298.73\n",
      "[SPARC][INFO] Steps: 1000, Epot: -441.527315, Ekin: 0.368242, Temp: 356.11\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]                     Model Path: iter_000000/01.train                    \n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]                       Using the following models:                       \n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]            iter_000000/01.train/training_1/frozen_model_1.pb            \n",
      "[SPARC][INFO]            iter_000000/01.train/training_2/frozen_model_2.pb            \n",
      "[SPARC][INFO] ========================================================================\n",
      "2026-02-20 14:25:58.846599: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-20 14:25:58.880190: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-20 14:25:59.323249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:tensorflow:From /home/wazel/anaconda3/envs/notebook/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:root:To get the best performance, it is recommended to adjust the number of threads by setting the environment variables OMP_NUM_THREADS, TF_INTRA_OP_PARALLELISM_THREADS, and TF_INTER_OP_PARALLELISM_THREADS. See https://deepmd.rtfd.io/parallelism/ for more information.\n",
      "2026-02-20 14:26:00.162476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21990 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:26:00.163768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22158 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "2026-02-20 14:26:00.179507: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2026-02-20 14:26:00.270105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21990 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:55:00.0, compute capability: 8.9\n",
      "2026-02-20 14:26:00.271020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22158 MB memory:  -> device: 1, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:a2:00.0, compute capability: 8.9\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] !         Model deviation calculation completed successfully!          !\n",
      "[SPARC][INFO]          Results saved in: iter_000000/02.dpmd/model_dev_0.out          \n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO] \n",
      "==========================================================================================\n",
      "[SPARC][INFO] Found 25 candidates for labelling within range [0.05, 0.30] eV/Å\n",
      "[SPARC][INFO] ==========================================================================================\n",
      "[SPARC][INFO] Generated POSCAR file for structure 0 in iter_000000/02.dpmd/dft_candidates/0001/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 2 in iter_000000/02.dpmd/dft_candidates/0002/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 3 in iter_000000/02.dpmd/dft_candidates/0003/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 4 in iter_000000/02.dpmd/dft_candidates/0004/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 5 in iter_000000/02.dpmd/dft_candidates/0005/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 6 in iter_000000/02.dpmd/dft_candidates/0006/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 7 in iter_000000/02.dpmd/dft_candidates/0007/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 8 in iter_000000/02.dpmd/dft_candidates/0008/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 9 in iter_000000/02.dpmd/dft_candidates/0009/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 10 in iter_000000/02.dpmd/dft_candidates/0010/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 11 in iter_000000/02.dpmd/dft_candidates/0011/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 12 in iter_000000/02.dpmd/dft_candidates/0012/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 13 in iter_000000/02.dpmd/dft_candidates/0013/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 14 in iter_000000/02.dpmd/dft_candidates/0014/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 15 in iter_000000/02.dpmd/dft_candidates/0015/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 16 in iter_000000/02.dpmd/dft_candidates/0016/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 17 in iter_000000/02.dpmd/dft_candidates/0017/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 18 in iter_000000/02.dpmd/dft_candidates/0018/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 19 in iter_000000/02.dpmd/dft_candidates/0019/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 20 in iter_000000/02.dpmd/dft_candidates/0020/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 21 in iter_000000/02.dpmd/dft_candidates/0021/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 22 in iter_000000/02.dpmd/dft_candidates/0022/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 23 in iter_000000/02.dpmd/dft_candidates/0023/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 24 in iter_000000/02.dpmd/dft_candidates/0024/\n",
      "[SPARC][INFO] Generated POSCAR file for structure 25 in iter_000000/02.dpmd/dft_candidates/0025/\n",
      "[SPARC][INFO] Candidates found for labelling: True\n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]                 Active Learning Protocol is set to: True                \n",
      "[SPARC][INFO] ========================================================================\n",
      "[SPARC][INFO]                    Total AL Iterations will be run: 1                   \n"
     ]
    }
   ],
   "source": [
    "# Run workflow\n",
    "!sparc -i input.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5d01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
